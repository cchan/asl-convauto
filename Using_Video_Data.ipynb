{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempting to load rawdata.pickle...\n",
      "Success\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Input, Dense\n",
    "from keras.models import load_model, Sequential\n",
    "import numpy as np\n",
    "\n",
    "encoding_dim = 32\n",
    "image_x, image_y = (336, 300)\n",
    "image_dim = image_x * image_y\n",
    "\n",
    "import csv\n",
    "import os\n",
    "from multiprocessing import Process, Lock, Manager\n",
    "\n",
    "def run(psID, data, fnames, printlock, datalock):\n",
    "    with printlock:\n",
    "      print(\"Subprocess \"+str(psID)+\" starting!\")\n",
    "    try:\n",
    "      while True:\n",
    "        fname = fnames.pop()\n",
    "        if fname.endswith(\"0.csv\"):\n",
    "          with printlock:\n",
    "            print(fname)\n",
    "          with open(\"../csv/\" + fname, \"r\") as file:\n",
    "            try:\n",
    "              file_frames = []\n",
    "              while True:\n",
    "                curr = len(file_frames)\n",
    "                file_frames.append(bytearray())\n",
    "                #with printlock:\n",
    "                #  print \"Starting\", curr\n",
    "                #  print len(data)\n",
    "                while True:\n",
    "                  line = next(file)\n",
    "                  if len(line) <= 1:\n",
    "                    break\n",
    "                  file_frames[curr].extend(int(i) for i in line.split(','))\n",
    "            except StopIteration:\n",
    "              with datalock:\n",
    "                data.extend(file_frames)\n",
    "    except IndexError:\n",
    "      with printlock:\n",
    "        print(\"Subprocess \"+str(psID)+\" exiting!\")\n",
    "\n",
    "import cPickle as pickle\n",
    "try:\n",
    "  print \"Attempting to load rawdata.pickle...\"\n",
    "  with open(\"rawdata.pickle\", \"r\") as f:\n",
    "    data = pickle.load(f)\n",
    "  print \"Success\"\n",
    "except IOError:\n",
    "  print \"Failed, loading from ../csv...\"\n",
    "  with Manager() as manager:\n",
    "    data = manager.list()\n",
    "    fnames = manager.list(os.listdir(\"../csv\"))\n",
    "    printlock = Lock()\n",
    "    datalock = Lock()\n",
    "\n",
    "    nCores = 40\n",
    "    processes = []\n",
    "    for i in range(nCores):\n",
    "      p = Process(target = run, args = (i,data,fnames,printlock,datalock))\n",
    "      processes.append(p)\n",
    "\n",
    "    for p in processes:\n",
    "      p.start()\n",
    "    for p in processes:\n",
    "      p.join()\n",
    "\n",
    "    data = list(data)\n",
    "\n",
    "    print(\"Done! Pickling...\")\n",
    "\n",
    "    with open(\"rawdata.pickle\", \"wb\") as p:\n",
    "      pickle.dump(data, p, 2)\n",
    "\n",
    "    print(\"Wrote rawdata.pickle\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [[int(x) for x in ba] for ba in data if len(ba) == 100800]\n",
    "\n",
    "\n",
    "import math\n",
    "d = int(math.floor(0.8 * len(data)))\n",
    "x_train = np.array(data[:d])\n",
    "x_test = np.array(data[d:])\n",
    "\n",
    "#from keras.datasets import mnist\n",
    "#x_train = x_train.astype('float32') / 255.\n",
    "#x_test = x_test.astype('float32') / 255.\n",
    "#x_train = x_train.reshape((len(x_train), np.prod(x_train.shape[1:])))\n",
    "#x_test = x_test.reshape((len(x_test), np.prod(x_test.shape[1:])))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Tensor(\"Shape_10:0\", shape=(2,), dtype=int32)'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.backend import shape\n",
    "str(shape(x_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "try:\n",
    "  print(\"Attempting to load model...\")\n",
    "  autoencoder = load_model('model.h5')\n",
    "  print(\"Success.\")\n",
    "except IOError:\n",
    "  print(\"Failed, training a model.\")\n",
    "  autoencoder = Sequential([\n",
    "    Dense(image_dim * 2, activation = 'relu', input_dim = image_dim),\n",
    "    Dense(encoding_dim, activation='relu'),\n",
    "    Dense(image_dim * 2, activation = 'relu'),\n",
    "    Dense(image_dim, activation='sigmoid')\n",
    "  ])\n",
    "\n",
    "  autoencoder.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "  autoencoder.fit(x_train, x_train,\n",
    "#                epochs=5,\n",
    "#                batch_size=1,\n",
    "#                shuffle=True,\n",
    "#                validation_data=(x_test, x_test)\n",
    "  )\n",
    "  print \"Done training. Saving model.h5...\"\n",
    "  autoencoder.save('model.h5')\n",
    "  print \"Saved.\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# encode and decode some digits\n",
    "# note that we take them from the *test* set\n",
    "#decoded_imgs = get_activations(autoencoder, -1, x_test)\n",
    "decoded_imgs = autoencoder.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# use Matplotlib (don't ask)\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "n = 10  # how many digits we will display\n",
    "plt.figure(figsize=(20, 4))\n",
    "for i in range(n):\n",
    "    # display original\n",
    "    ax = plt.subplot(2, n, i + 1)\n",
    "    plt.imshow(x_test[i].reshape(image_x, image_y))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "\n",
    "    # display reconstruction\n",
    "    ax = plt.subplot(2, n, i + 1 + n)\n",
    "    plt.imshow(decoded_imgs[i].reshape(image_x, image_y))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#from keras import backend as K\n",
    "#def get_activations(model, layer, X_batch):\n",
    "#    get_activations = K.function([model.layers[0].input, K.learning_phase()], [model.layers[layer].output,])\n",
    "#    activations = get_activations([X_batch,0])\n",
    "#    return activations\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
